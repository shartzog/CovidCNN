{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from itertools import permutations\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pyodbc\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "from random import randrange\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "plt.ion()   # interactive mode\n",
    "testimages = list()\n",
    "testclasses = list()\n",
    "testindices = list()\n",
    "testinitialized = 0\n",
    "PATH = './test_net4.tar'\n",
    "ndepth = 4\n",
    "nminibatchsize = 16\n",
    "classes = ('Hospitalized','Intubated','Deceased','Pneumonia')\n",
    "columns = ('Male','Pregnant','Diabetes','Asthma','Immunocompromised'\n",
    "            ,'Hypertension','Other Disease','Cardiovascular Disease','Obesity','Kidney Disease'\n",
    "            ,'Tobacco Use','COPD')\n",
    "nclasses = len(classes)\n",
    "ncolumns = len(columns)\n",
    "testratio = 0.4 #randomly select this proportion of the dataset to be test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total features: 1320; image size: 37 x 37 x 4\nimage normalization tuple:\n(0.5, 0.5, 0.5, 0.5)\n"
    }
   ],
   "source": [
    "nfeatures = 1.0\n",
    "for i in range(ndepth-1):\n",
    "    nfeatures *= (ncolumns - i)\n",
    "nimgsize = math.ceil(nfeatures**0.5)\n",
    "npix = nimgsize**2\n",
    "normtuple = list()\n",
    "for i in range(ndepth): normtuple.extend([0.5])\n",
    "normtuple = tuple(normtuple)\n",
    "\n",
    "print('total features: %i; image size: %i x %i x %i' % (nfeatures,nimgsize,nimgsize,ndepth))\n",
    "print('image normalization tuple:')\n",
    "print(normtuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlabelval(labeldata):\n",
    "    retval = np.array(list(labeldata),dtype=np.float32)\n",
    "    return retval\n",
    "\n",
    "def createimagetensor(row=None):\n",
    "    if row:\n",
    "        icol = 0\n",
    "        irow = 0\n",
    "        if len(list(row[0])) != ncolumns: raise CustomError('Invalid Input Size: Expected %i, Received %i' % (ncolumns,len(list(row[0]))))\n",
    "        if len(row) < 2: raise CustomError('Invalid Data: Expected row format is [bindata,age,labels(optional)]')\n",
    "        imgdata = np.zeros((nimgsize,nimgsize,ndepth),dtype=np.float32)\n",
    "        for px in permutations(list(row[0]),ndepth-1):\n",
    "            thispx = list()\n",
    "            for chan in px: thispx.extend([float(chan)])\n",
    "            thispx.extend([float(row[1])/100.])\n",
    "            imgdata[icol,irow,:] = thispx\n",
    "            irow += 1\n",
    "            if (irow > nimgsize - 1):\n",
    "                icol += 1\n",
    "                irow = 0\n",
    "        return TF.normalize(TF.to_tensor(imgdata),normtuple,normtuple)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "class CustomError(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create generator function for data acquisition and conversion to torch image format.\n",
    "#function must return a tuple of form (tensor containing 4 images,tensor containing 4 labels)\n",
    "#also builds a test set using a quick and dirty random number method.  this will need to be \n",
    "#improved to balance both the test and train sets across potential labels.\n",
    "\n",
    "def nextrow():\n",
    "    conn = pyodbc.connect('DSN=covid;UID=seh;PWD=Welcome2020!;')\n",
    "    crsr = conn.cursor()\n",
    "    crsr.execute(\"{CALL getpydatav2}\")\n",
    "    rowcnt = 0\n",
    "    imgs = list()\n",
    "    labels = list()\n",
    "    row = [0,1,2]\n",
    "    idx = 0\n",
    "    while row:\n",
    "        while (rowcnt<nminibatchsize):\n",
    "            if testinitialized == 1 and idx in testindices:\n",
    "                crsr.skip(nminibatchsize)\n",
    "                row = [0,1,2]\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    row = crsr.fetchone()\n",
    "                except:\n",
    "                    conn = pyodbc.connect('DSN=covid;UID=seh;PWD=Welcome2020!;')\n",
    "                    crsr = conn.cursor()\n",
    "                    crsr.execute(\"{CALL getpydatav2}\")\n",
    "                    crsr.skip(idx*nminibatchsize + rowcnt)\n",
    "                    row = crsr.fetchone()\n",
    "                rowcnt += 1\n",
    "                if row:\n",
    "                    imgtensor = createimagetensor(row)\n",
    "                    labels.append(np.array(list(row[2]),dtype=np.float32))\n",
    "                    imgs.append(imgtensor)\n",
    "                else:\n",
    "                    break\n",
    "        if row:\n",
    "            if (testinitialized == 0):\n",
    "                if (random() < testratio):\n",
    "                    testimages.append(torch.stack(imgs))\n",
    "                    testclasses.append(torch.tensor(labels))\n",
    "                    testindices.append(idx)\n",
    "                else:\n",
    "                    yield torch.stack(imgs),torch.tensor(labels)\n",
    "            elif (idx not in testindices):\n",
    "                yield torch.stack(imgs),torch.tensor(labels)\n",
    "            rowcnt = 0\n",
    "            idx += 1\n",
    "            imgs = list()\n",
    "            labels = list()\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create generator function for test set\n",
    "def gentestdata(startindex = 0):\n",
    "    for i,clss in enumerate(testclasses[startindex:],startindex):\n",
    "        yield testimages[i],clss\n",
    "\n",
    "def gettestdata(idx = 0):\n",
    "    return testimages[idx],testclasses[idx]\n",
    "\n",
    "def createfakedata(age=None, conds=None):\n",
    "    if age is None: age = randrange(15,90)\n",
    "    elif isinstance(age,tuple): age = randrange(age[0],age[1])\n",
    "    bindata = ''\n",
    "    if isinstance(conds,list):\n",
    "        for col in columns:\n",
    "            bindata += ('1' if col in conds else '0') \n",
    "        return createimagetensor([bindata,age]).unsqueeze(0)\n",
    "    elif isinstance(conds,str):\n",
    "        for col in columns:\n",
    "            bindata += ('1' if col in conds else '0') \n",
    "        return createimagetensor([bindata,age]).unsqueeze(0)\n",
    "    totconds = (conds if isinstance(conds,int) and conds < ncolumns else math.floor(ncolumns*random()))\n",
    "    condsapplied = 0\n",
    "    for i,col in enumerate(columns):\n",
    "        if condsapplied < totconds:\n",
    "            if random() >= 0.5:\n",
    "                if i == 1 and (age < 12 or age > 55 or bindata[0] == '1'):\n",
    "                    bindata += '0'\n",
    "                else:\n",
    "                    bindata += '1'\n",
    "                    condsapplied += 1\n",
    "            else:\n",
    "                bindata += '0'\n",
    "        else:\n",
    "            bindata += '0'\n",
    "    return createimagetensor([bindata,age]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, modelinputtensor, layerlist, layerparams):\n",
    "        \"\"\"\n",
    "        torch.nn must be imported as nn\n",
    "        torch.nn.functional must be imported as F\n",
    "        modelinputtensor = example model input tensor (including an arbitrary batch dimension)\n",
    "        layerlist = list of pytorch nn fucntions as their 'F' namespace equivalents (e.g. 'nn.MaxPool2d' should be supplied as 'F.max_pool2d') \n",
    "        layerparams = list of _independent_ params in their nn form and passed as a tuple.  Example:\n",
    "            The first conv2d layer will have 3 params in a tuple of form (in_channels, out_channels, kernel_size). \n",
    "            Subsequent conv2d layers will have _2_ params in a tuple of form (out_channels, kernel_size) since the in_channels will be determined by the previous layer. \n",
    "            Pooling layers will always have params of the form (x, y) corresponding to the pooling window size.\n",
    "            Linear layers will always have a single param corresponding to the number of out features for the layer (input features are determined by the preceding layer)\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.lyrs, self.fwdlyrs = self.getlayers(modelinputtensor,layerlist,layerparams)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for f in self.fwdlyrs:\n",
    "            x = eval(f)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "    def getlayers(self,testtensor,funcs=[],params=[],debug=0):\n",
    "        initlayers = nn.ModuleList()\n",
    "        fwdlayers = list()\n",
    "        if debug == 1: print(testtensor.size())\n",
    "        lastsize = None\n",
    "        lyr = 0\n",
    "        with torch.no_grad():\n",
    "            for fn,pa in zip(funcs,params):\n",
    "                if lastsize is not None:\n",
    "                    if fn.__name__ == 'conv2d':\n",
    "                        pa = (lastsize[1],pa[0],pa[1])\n",
    "                    elif fn.__name__ == 'linear':\n",
    "                        if not testtensor.ndim == 2:\n",
    "                            testtensor = testtensor.view(-1,self.numflatfeatures(testtensor))\n",
    "                            fwdlayers.append(\"x.view(-1,self.numflatfeatures(x))\")\n",
    "                            lastsize = testtensor.size()\n",
    "                        pa = (lastsize[1],pa)        \n",
    "                if fn.__name__ == 'conv2d':\n",
    "                    paeval = \"torch.tensor(np.random.rand(\" + \",\".join(tuple(map(str,(pa[1],pa[0],pa[2],pa[2])))) + \"),dtype=torch.float32)\"\n",
    "                elif fn.__name__ == 'max_pool2d':\n",
    "                    paeval = \",\".join(tuple(map(str,pa)))\n",
    "                elif fn.__name__ == 'linear':\n",
    "                    paeval = \"torch.tensor(np.random.rand(\" + \",\".join(tuple(map(str,(pa[1],pa[0])))) + \"),dtype=torch.float32)\"\n",
    "                if not fn.__name__ == 'linear' or pa[0] > pa[1]:\n",
    "                    testtensor = fn(testtensor,eval(paeval))\n",
    "                    lastsize = testtensor.size()\n",
    "                    initlayers.append(eval(self.getinitequivalent(fn.__name__,pa)))\n",
    "                    fwdlayers.append(self.getfwdequivalent(fn.__name__,lyr))\n",
    "                    lyr += 1\n",
    "                    if debug == 1: print(testtensor.size())\n",
    "                elif debug == 1: print('Eliminating linear layer - out features > previous layer')\n",
    "        fwdlayers[-1] = 'self.lyrs[' + str(lyr - 1) + '](x)'\n",
    "        return initlayers,fwdlayers\n",
    "\n",
    "    def numflatfeatures(self,x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    def getinitequivalent(self,funcname,initparams):\n",
    "        return 'nn.' + ''.join([val.capitalize() for val in funcname.split('_')]) + '(' + \",\".join(tuple(map(str,initparams))) + ')'\n",
    "\n",
    "    def getfwdequivalent(self,funcname,lyrnum):\n",
    "        if not funcname == 'max_pool2d':\n",
    "            return 'F.relu(self.lyrs[' + str(lyrnum) + '](x))'\n",
    "        else:\n",
    "            return 'self.lyrs[' + str(lyrnum) + '](x)'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getconvlayers(firstdepth=4,maxlayers=5,minlayers=1,maxkernel=7,minkernel=3,maxoutchan=12,minoutchan=4):\n",
    "    fncs,parms = list(),list()\n",
    "    fncs.append(F.conv2d)\n",
    "    parms.append((firstdepth,np.random.randint(minoutchan,maxoutchan+1),np.random.randint(minkernel,maxkernel+1)))\n",
    "    for i in range(np.random.randint(minlayers-1,maxlayers)):\n",
    "        fncs.append(F.conv2d)\n",
    "        parms.append((np.random.randint(minoutchan,maxoutchan+1),np.random.randint(minkernel,maxkernel+1)))\n",
    "    return fncs,parms\n",
    "\n",
    "def getlinlayers(initoutfeatures,featuredeadband=20,maxlayerdivisor=20,minlayerdivisor=4):\n",
    "    fncs,parms = list(),list()\n",
    "    fncs.append(F.linear)\n",
    "    parms.append(initoutfeatures)\n",
    "    nextoutfeatures = int(initoutfeatures/np.random.randint(minlayerdivisor,maxlayerdivisor+1)) \n",
    "    while nextoutfeatures > nclasses + featuredeadband:\n",
    "        fncs.append(F.linear)\n",
    "        parms.append(nextoutfeatures)\n",
    "        nextoutfeatures = int(nextoutfeatures/np.random.randint(minlayerdivisor,maxlayerdivisor+1))\n",
    "    fncs.append(F.linear)\n",
    "    parms.append(nclasses)\n",
    "    return fncs,parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 100/100 [00:10<00:00,  9.30it/s]\n"
    }
   ],
   "source": [
    "datlist = []\n",
    "for i in range(4):\n",
    "    datlist.append(createfakedata(40,[\"Diabetes\"]).squeeze(0))\n",
    "testtensor = torch.stack(datlist)\n",
    "optimizers = [(\"optim.SGD(d['net'].parameters(), lr=0.0001, momentum=0.9)\",\"SGD lr=1 p=.9\"),\n",
    "              (\"optim.Adam(d['net'].parameters(), lr=0.0001)\",\"lr=1 Adam\"),\n",
    "              (\"optim.Adam(d['net'].parameters(), lr=0.00001)\",\"lr=0.1 Adam\"),\n",
    "             ]\n",
    "def createtestnets(netcount=50,**kwargs):\n",
    "    netdict = dict()\n",
    "    for i in tqdm(range(netcount)):\n",
    "        cfs, cps = getconvlayers()\n",
    "        lfs, lps = getlinlayers(1000)\n",
    "        funcs = cfs\n",
    "        params = cps\n",
    "        if random() > 0.3:\n",
    "            funcs.extend([F.max_pool2d])\n",
    "            poolsize = np.random.randint(2,4)\n",
    "            params.extend([(poolsize,poolsize)])\n",
    "        funcs.extend(lfs)\n",
    "        params.extend(lps)\n",
    "        for opt in optimizers:\n",
    "            d = dict()\n",
    "            d['net'] = Net(testtensor,funcs,params)\n",
    "            d['criterion'] = nn.BCELoss()\n",
    "            d['optimizer'] = eval(opt[0])\n",
    "            #d['net'].cuda()\n",
    "            netdict[str(i) + '-' + opt[1]] = d\n",
    "    return netdict\n",
    "\n",
    "netcount = 100\n",
    "netdict = createtestnets(netcount)\n",
    "funcs = [F.conv2d,F.conv2d,F.max_pool2d,F.linear,F.linear,F.linear]\n",
    "params = [(4,12,5),(48,5),(2,2),578,34,4]\n",
    "for opt in optimizers:\n",
    "    d = dict()\n",
    "    d['net'] = Net(testtensor,funcs,params)\n",
    "    d['criterion'] = nn.BCELoss()\n",
    "    d['optimizer'] = eval(opt[0])#optim.SGD(d['net'].parameters(), lr=0.0001, momentum=0.9)\n",
    "    #d['net'].cuda()\n",
    "#print(summary(d['net'],(ndepth,nimgsize,nimgsize)))\n",
    "    netdict[str(netcount) + '-' + opt[1]] = d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net number 0\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b5d724af3469>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Net number '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'net'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndepth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnimgsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnimgsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a76048afffc1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfwdlyrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 415\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "for n in range(netcount+1):\n",
    "    for o in optimizers:\n",
    "        print('Net number ' + str(n))\n",
    "        print(summary(netdict[str(n) + '-' + o[1]]['net'],(ndepth,nimgsize,nimgsize)))\n",
    "        print()\n",
    "        print()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./train_test_data.tar')\n",
    "train_data = checkpoint['train_data']\n",
    "testimages = checkpoint['testimages']\n",
    "testindices = checkpoint['testindices']\n",
    "testclasses = checkpoint['testclasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./train_test_data.tar')\n",
    "train_data = checkpoint['train_data']\n",
    "testimages = checkpoint['testimages']\n",
    "testindices = checkpoint['testindices']\n",
    "testclasses = checkpoint['testclasses']\n",
    "torch.save({'train_data':train_data,\n",
    "            'validation_images':testimages,\n",
    "            'validation_indices': testindices,\n",
    "            'validation_labels': testclasses,\n",
    "            },'./datasets.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = list()\n",
    "rowgen = nextrow()\n",
    "pbar = tqdm(enumerate(rowgen),total=1200)\n",
    "for i, data in pbar:\n",
    "    train_data.append(data)\n",
    "testinitialized = 1\n",
    "torch.save({'train_data':train_data,\n",
    "            'testimages':testimages,\n",
    "            'testindices': testindices,\n",
    "            'testclasses': testclasses,\n",
    "            },'./train_test_data.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "net name: 0-SGD lr=1 p=.9; loss: 0.663: 100%|██████████| 1290/1290 [00:04<00:00, 261.39it/s]\nnet name: 0-SGD lr=1 p=.9; loss: 0.663; validation loss: 0.642: 100%|██████████| 834/834 [00:01<00:00, 609.35it/s]\nnet name: 0-lr=1 Adam; loss: 0.469: 100%|██████████| 1290/1290 [00:03<00:00, 326.93it/s]\nnet name: 0-lr=1 Adam; loss: 0.469; validation loss: 0.443: 100%|██████████| 834/834 [00:00<00:00, 861.95it/s]\nnet name: 0-lr=0.1 Adam; loss: 0.542: 100%|██████████| 1290/1290 [00:03<00:00, 329.91it/s]\nnet name: 0-lr=0.1 Adam; loss: 0.542; validation loss: 0.469: 100%|██████████| 834/834 [00:00<00:00, 860.21it/s]\nnet name: 1-SGD lr=1 p=.9; loss: 0.653: 100%|██████████| 1290/1290 [00:03<00:00, 387.08it/s]\nnet name: 1-SGD lr=1 p=.9; loss: 0.653; validation loss: 0.637: 100%|██████████| 834/834 [00:00<00:00, 895.61it/s]\nnet name: 1-lr=1 Adam; loss: 0.478: 100%|██████████| 1290/1290 [00:03<00:00, 334.36it/s]\nnet name: 1-lr=1 Adam; loss: 0.478; validation loss: 0.446: 100%|██████████| 834/834 [00:00<00:00, 881.94it/s]\nnet name: 1-lr=0.1 Adam; loss: 0.560: 100%|██████████| 1290/1290 [00:03<00:00, 323.45it/s]\nnet name: 1-lr=0.1 Adam; loss: 0.560; validation loss: 0.482: 100%|██████████| 834/834 [00:00<00:00, 912.19it/s]\nnet name: 2-SGD lr=1 p=.9; loss: 0.525: 100%|██████████| 1290/1290 [00:03<00:00, 340.77it/s]\nnet name: 2-SGD lr=1 p=.9; loss: 0.525; validation loss: 0.469: 100%|██████████| 834/834 [00:00<00:00, 1012.79it/s]\nnet name: 2-lr=1 Adam; loss: 0.443: 100%|██████████| 1290/1290 [00:05<00:00, 243.59it/s]\nnet name: 2-lr=1 Adam; loss: 0.443; validation loss: 0.437: 100%|██████████| 834/834 [00:00<00:00, 1006.67it/s]\nnet name: 2-lr=0.1 Adam; loss: 0.464: 100%|██████████| 1290/1290 [00:05<00:00, 241.55it/s]\nnet name: 2-lr=0.1 Adam; loss: 0.464; validation loss: 0.439: 100%|██████████| 834/834 [00:00<00:00, 983.27it/s]\nnet name: 3-SGD lr=1 p=.9; loss: 0.548: 100%|██████████| 1290/1290 [00:01<00:00, 706.42it/s]\nnet name: 3-SGD lr=1 p=.9; loss: 0.548; validation loss: 0.492: 100%|██████████| 834/834 [00:00<00:00, 1260.72it/s]\nnet name: 3-lr=1 Adam; loss: 0.455: 100%|██████████| 1290/1290 [00:02<00:00, 587.12it/s]\nnet name: 3-lr=1 Adam; loss: 0.455; validation loss: 0.439: 100%|██████████| 834/834 [00:00<00:00, 1240.24it/s]\nnet name: 3-lr=0.1 Adam; loss: 0.517: 100%|██████████| 1290/1290 [00:02<00:00, 585.27it/s]\nnet name: 3-lr=0.1 Adam; loss: 0.517; validation loss: 0.472: 100%|██████████| 834/834 [00:00<00:00, 1253.85it/s]\nnet name: 4-SGD lr=1 p=.9; loss: 0.550: 100%|██████████| 1290/1290 [00:03<00:00, 349.39it/s]\nnet name: 4-SGD lr=1 p=.9; loss: 0.550; validation loss: 0.477: 100%|██████████| 834/834 [00:00<00:00, 992.63it/s]\nnet name: 4-lr=1 Adam; loss: 0.444: 100%|██████████| 1290/1290 [00:05<00:00, 253.36it/s]\nnet name: 4-lr=1 Adam; loss: 0.444; validation loss: 0.438: 100%|██████████| 834/834 [00:00<00:00, 908.00it/s]\nnet name: 4-lr=0.1 Adam; loss: 0.473: 100%|██████████| 1290/1290 [00:05<00:00, 254.78it/s]\nnet name: 4-lr=0.1 Adam; loss: 0.473; validation loss: 0.442: 100%|██████████| 834/834 [00:00<00:00, 981.42it/s]\nnet name: 5-SGD lr=1 p=.9; loss: 0.682: 100%|██████████| 1290/1290 [00:04<00:00, 296.29it/s]\nnet name: 5-SGD lr=1 p=.9; loss: 0.682; validation loss: 0.662: 100%|██████████| 834/834 [00:00<00:00, 854.03it/s]\nnet name: 5-lr=1 Adam; loss: 0.452: 100%|██████████| 1290/1290 [00:05<00:00, 233.36it/s]\nnet name: 5-lr=1 Adam; loss: 0.452; validation loss: 0.438: 100%|██████████| 834/834 [00:00<00:00, 846.89it/s]\nnet name: 5-lr=0.1 Adam; loss: 0.486: 100%|██████████| 1290/1290 [00:05<00:00, 222.73it/s]\nnet name: 5-lr=0.1 Adam; loss: 0.486; validation loss: 0.441: 100%|██████████| 834/834 [00:01<00:00, 804.58it/s]\nnet name: 6-SGD lr=1 p=.9; loss: 0.686: 100%|██████████| 1290/1290 [00:04<00:00, 308.36it/s]\nnet name: 6-SGD lr=1 p=.9; loss: 0.686; validation loss: 0.668: 100%|██████████| 834/834 [00:01<00:00, 828.59it/s]\nnet name: 6-lr=1 Adam; loss: 0.450: 100%|██████████| 1290/1290 [00:05<00:00, 234.57it/s]\nnet name: 6-lr=1 Adam; loss: 0.450; validation loss: 0.438: 100%|██████████| 834/834 [00:00<00:00, 834.38it/s]\nnet name: 6-lr=0.1 Adam; loss: 0.495: 100%|██████████| 1290/1290 [00:05<00:00, 238.04it/s]\nnet name: 6-lr=0.1 Adam; loss: 0.495; validation loss: 0.462: 100%|██████████| 834/834 [00:01<00:00, 829.43it/s]\nnet name: 7-SGD lr=1 p=.9; loss: 0.529: 100%|██████████| 1290/1290 [00:04<00:00, 296.49it/s]\nnet name: 7-SGD lr=1 p=.9; loss: 0.529; validation loss: 0.477: 100%|██████████| 834/834 [00:00<00:00, 918.96it/s]\nnet name: 7-lr=1 Adam; loss: 0.442: 100%|██████████| 1290/1290 [00:06<00:00, 190.73it/s]\nnet name: 7-lr=1 Adam; loss: 0.442; validation loss: 0.437: 100%|██████████| 834/834 [00:00<00:00, 946.44it/s]\nnet name: 7-lr=0.1 Adam; loss: 0.450: 100%|██████████| 1290/1290 [00:06<00:00, 188.23it/s]\nnet name: 7-lr=0.1 Adam; loss: 0.450; validation loss: 0.438: 100%|██████████| 834/834 [00:00<00:00, 959.11it/s]\nnet name: 8-SGD lr=1 p=.9; loss: 0.675: 100%|██████████| 1290/1290 [00:03<00:00, 411.66it/s]\nnet name: 8-SGD lr=1 p=.9; loss: 0.675; validation loss: 0.660: 100%|██████████| 834/834 [00:00<00:00, 893.42it/s]\nnet name: 8-lr=1 Adam; loss: 0.464: 100%|██████████| 1290/1290 [00:03<00:00, 350.14it/s]\nnet name: 8-lr=1 Adam; loss: 0.464; validation loss: 0.440: 100%|██████████| 834/834 [00:00<00:00, 905.05it/s]\nnet name: 8-lr=0.1 Adam; loss: 0.565: 100%|██████████| 1290/1290 [00:03<00:00, 349.70it/s]\nnet name: 8-lr=0.1 Adam; loss: 0.565; validation loss: 0.484: 100%|██████████| 834/834 [00:00<00:00, 905.03it/s]\nnet name: 9-SGD lr=1 p=.9; loss: 0.580: 100%|██████████| 1290/1290 [00:03<00:00, 427.98it/s]\nnet name: 9-SGD lr=1 p=.9; loss: 0.580; validation loss: 0.479: 100%|██████████| 834/834 [00:00<00:00, 964.02it/s]\nnet name: 9-lr=1 Adam; loss: 0.448: 100%|██████████| 1290/1290 [00:03<00:00, 362.15it/s]\nnet name: 9-lr=1 Adam; loss: 0.448; validation loss: 0.438: 100%|██████████| 834/834 [00:00<00:00, 968.08it/s]\nnet name: 9-lr=0.1 Adam; loss: 0.496: 100%|██████████| 1290/1290 [00:03<00:00, 363.88it/s]\nnet name: 9-lr=0.1 Adam; loss: 0.496; validation loss: 0.441: 100%|██████████| 834/834 [00:00<00:00, 963.27it/s]\nnet name: 10-SGD lr=1 p=.9; loss: 0.595: 100%|██████████| 1290/1290 [00:02<00:00, 442.00it/s]\nnet name: 10-SGD lr=1 p=.9; loss: 0.595; validation loss: 0.487: 100%|██████████| 834/834 [00:00<00:00, 935.82it/s]\nnet name: 10-lr=1 Adam; loss: 0.445: 100%|██████████| 1290/1290 [00:03<00:00, 352.68it/s]\nnet name: 10-lr=1 Adam; loss: 0.445; validation loss: 0.438: 100%|██████████| 834/834 [00:00<00:00, 1005.45it/s]\nnet name: 10-lr=0.1 Adam; loss: 0.484: 100%|██████████| 1290/1290 [00:03<00:00, 357.36it/s]\nnet name: 10-lr=0.1 Adam; loss: 0.484; validation loss: 0.441: 100%|██████████| 834/834 [00:00<00:00, 981.74it/s]\nnet name: 11-SGD lr=1 p=.9; loss: 0.561: 100%|██████████| 1290/1290 [00:02<00:00, 598.02it/s]\nnet name: 11-SGD lr=1 p=.9; loss: 0.561; validation loss: 0.475: 100%|██████████| 834/834 [00:00<00:00, 1106.31it/s]\nnet name: 11-lr=1 Adam; loss: 0.452: 100%|██████████| 1290/1290 [00:02<00:00, 486.39it/s]\nnet name: 11-lr=1 Adam; loss: 0.452; validation loss: 0.440: 100%|██████████| 834/834 [00:00<00:00, 1081.47it/s]\nnet name: 11-lr=0.1 Adam; loss: 0.514: 100%|██████████| 1290/1290 [00:02<00:00, 469.83it/s]\nnet name: 11-lr=0.1 Adam; loss: 0.514; validation loss: 0.454: 100%|██████████| 834/834 [00:00<00:00, 1047.13it/s]\nnet name: 12-SGD lr=1 p=.9; loss: 0.691: 100%|██████████| 1290/1290 [00:03<00:00, 340.25it/s]\nnet name: 12-SGD lr=1 p=.9; loss: 0.691; validation loss: 0.675: 100%|██████████| 834/834 [00:01<00:00, 739.61it/s]\nnet name: 12-lr=1 Adam; loss: 0.475:  47%|████▋     | 600/1290 [00:02<00:02, 271.65it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-676b25b4cbfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print((outputs,labels))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train a series of layer configurations and record loss data\n",
    "loss_recording_rate = 10\n",
    "lossdict = dict()\n",
    "#for epoch in range(2):  # loop over the dataset multiple times\n",
    "for k,d in netdict.items():\n",
    "    net = d['net']\n",
    "    net.cuda()\n",
    "    net.train()\n",
    "    criterion = d['criterion']\n",
    "    optimizer = d['optimizer'] \n",
    "    tlosslist = []\n",
    "    vlosslist = []\n",
    "    last_loss = 0.0\n",
    "    lasttestidx = 0\n",
    "    running_loss = 0.0\n",
    "    testcnt = 0\n",
    "    train_cnt = len(train_data)\n",
    "    validationcnt = len(testimages)\n",
    "    #rowgen = nextrow()\n",
    "    #pbar = tqdm(enumerate(rowgen),total=validationfreq-1)\n",
    "    pbar = tqdm(enumerate(train_data),total=train_cnt)\n",
    "    for i, data in pbar:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print((outputs,labels))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
    "        if i % loss_recording_rate == loss_recording_rate - 1:\n",
    "            tlosslist.append((running_loss-last_loss)/loss_recording_rate)\n",
    "            pbar.set_description(desc='net name: %s; loss: %.3f' % (k, running_loss/(i+1)))\n",
    "            pbar.update()\n",
    "            last_loss = running_loss\n",
    "    last_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        randomstartindex = 0#math.floor(len(testimages)*random())\n",
    "        genfunc = gentestdata(randomstartindex)\n",
    "        pbar = tqdm(enumerate(genfunc),total=validationcnt)\n",
    "        for j, (tin,tlab) in pbar:\n",
    "            tin, tlab = tin.cuda(), tlab.cuda()\n",
    "            outputs = net(tin)\n",
    "            loss = criterion(outputs,tlab)\n",
    "            valid_loss += loss.item()\n",
    "            if j % loss_recording_rate == loss_recording_rate - 1:\n",
    "                vlosslist.append((valid_loss-last_loss)/loss_recording_rate)\n",
    "                last_loss = valid_loss\n",
    "                pbar.set_description(desc='net name: %s; loss: %.3f; validation loss: %.3f' \n",
    "                                        % (k, running_loss/train_cnt, valid_loss/(j+1)))\n",
    "                pbar.update()\n",
    "    #print('Training Complete for %s; loss: %.3f; validation loss: %.3f' % (k, running_loss/train_cnt, valid_loss/validationcnt))\n",
    "\n",
    "    lossdict[k] = {'trainlosses':tlosslist,\n",
    "                    'validlosses': vlosslist,\n",
    "                    'trainlossavg': running_loss / train_cnt,\n",
    "                    'validlossavg': valid_loss / validationcnt}\n",
    "    net.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "#save test set and model state dictionary for loading later without training.\n",
    "#torch.save({'model_state_dict':net.state_dict(),\n",
    "#            'testimages': testimages,\n",
    "#            'testclasses': testclasses,\n",
    "#            'testindices': testindices}, PATH)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,d in netdict.items():\n",
    "    d['net'].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(goodnets[0]['net'].lyrs)\n",
    "netdf = pd.DataFrame(columns=['netnum','iteration','loss','losstype'])\n",
    "loc = 0\n",
    "for k,gnet in netdict.items():\n",
    "    for i,loss in enumerate(lossdict[k]['trainlosses']):\n",
    "        netdf.loc[loc] = pd.Series({'netnum':k,'iteration':i,'loss':loss,'losstype':'train'})\n",
    "        loc += 1\n",
    "    for i,loss in enumerate(lossdict[k]['validlosses']):\n",
    "        netdf.loc[loc] = pd.Series({'netnum':k,'iteration':i,'loss':loss,'losstype':'test'})\n",
    "        loc += 1\n",
    "#agedf.loc[0] = pd.Series({'age':0,'type':'Predicted','result':'Deceased'})\n",
    "#print(netdf.iloc[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(netcount+1,1,figsize=(20,25))\n",
    "for i,ax in enumerate(axs):\n",
    "    sns.lineplot(ax=ax,x='iteration', y='loss', hue='netnum', style='losstype', data=netdf[netdf.netnum.str.startswith(str(i))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_summary_df = pd.DataFrame(columns=['net_number',\n",
    "                                       'param_count',\n",
    "                                       'conv_layers',\n",
    "                                       'has_pool',\n",
    "                                       'lin_layers',\n",
    "                                       'max_average_test_loss',\n",
    "                                       'max_loss_optimizer',\n",
    "                                       'max_loss_optimizer_efficiency',\n",
    "                                       'min_average_test_loss',\n",
    "                                       'min_loss_optimizer',\n",
    "                                       'min_loss_optimizer',\n",
    "                                       'min_loss_optimizer_efficiency'])\n",
    "last_net_num = 0\n",
    "param_count = 0\n",
    "conv_layers = 0\n",
    "has_pool = 0\n",
    "lin_layers = 0\n",
    "max_loss_optimizer = ''\n",
    "min_loss_optimizer = ''\n",
    "max_average_test_loss = 0.0\n",
    "min_average_test_loss = 1.0\n",
    "optimizer_type = ''\n",
    "loc = 0\n",
    "net_d = dict()\n",
    "for k,net_d in netdict.items():\n",
    "    net_number = int(k[:k.find('-')])\n",
    "    optimizer_type = k[k.find('-')+1:]\n",
    "    if last_net_num != net_number:\n",
    "        param_count = sum(p.numel() for p in net_d['net'].parameters() if p.requires_grad)\n",
    "        conv_layers = 0\n",
    "        has_pool = 0\n",
    "        lin_layers = 0\n",
    "        for lyr in net_d['net'].lyrs:\n",
    "            if str(lyr).startswith('Conv2d'):\n",
    "                conv_layers = conv_layers + 1 \n",
    "            if str(lyr).startswith('MaxPool'):\n",
    "                has_pool = 1 \n",
    "            if str(lyr).startswith('Linear'):\n",
    "                lin_layers = lin_layers + 1 \n",
    "        net_summary_df.loc[loc] = pd.Series({'net_number':last_net_num,\n",
    "                                             'param_count':param_count,\n",
    "                                             'conv_layers':conv_layers,\n",
    "                                             'has_pool':has_pool,\n",
    "                                             'lin_layers':lin_layers,\n",
    "                                             'max_average_test_loss':max_average_test_loss,\n",
    "                                             'max_loss_optimizer':max_loss_optimizer,\n",
    "                                             'max_loss_optimizer_efficiency':(1/(param_count*max_average_test_loss))*10000.0,\n",
    "                                             'min_average_test_loss':min_average_test_loss,\n",
    "                                             'min_loss_optimizer':min_loss_optimizer,\n",
    "                                             'min_loss_optimizer_efficiency':(1/(param_count*min_average_test_loss))*10000.0,\n",
    "                                             })\n",
    "        loc += 1\n",
    "        max_loss_optimizer = ''\n",
    "        min_loss_optimizer = ''\n",
    "        max_average_test_loss = 0.0\n",
    "        min_average_test_loss = 1.0\n",
    "    average_test_loss = netdf[netdf.netnum==k][netdf.losstype=='test'].loss.mean()\n",
    "    if average_test_loss < min_average_test_loss:\n",
    "        min_average_test_loss = average_test_loss\n",
    "        min_loss_optimizer = optimizer_type\n",
    "    if average_test_loss > max_average_test_loss:\n",
    "        max_average_test_loss = average_test_loss\n",
    "        max_loss_optimizer = optimizer_type\n",
    "    last_net_num = net_number\n",
    "\n",
    "param_count = sum(p.numel() for p in net_d['net'].parameters() if p.requires_grad)\n",
    "conv_layers = 0\n",
    "has_pool = 0\n",
    "lin_layers = 0\n",
    "for lyr in net_d['net'].lyrs:\n",
    "    if str(lyr).startswith('Conv2d'):\n",
    "        conv_layers = conv_layers + 1 \n",
    "    if str(lyr).startswith('MaxPool'):\n",
    "        has_pool = 1 \n",
    "    if str(lyr).startswith('Linear'):\n",
    "        lin_layers = lin_layers + 1 \n",
    "net_summary_df.loc[loc] = pd.Series({'net_number':net_number,\n",
    "                                        'param_count':param_count,\n",
    "                                        'conv_layers':conv_layers,\n",
    "                                        'has_pool':has_pool,\n",
    "                                        'lin_layers':lin_layers,\n",
    "                                        'max_average_test_loss':max_average_test_loss,\n",
    "                                        'max_loss_optimizer':max_loss_optimizer,\n",
    "                                        'max_loss_optimizer_efficiency':(1/(param_count*max_average_test_loss))*10000.0,\n",
    "                                        'min_average_test_loss':min_average_test_loss,\n",
    "                                        'min_loss_optimizer':min_loss_optimizer,\n",
    "                                        'min_loss_optimizer_efficiency':(1/(param_count*min_average_test_loss))*10000.0,\n",
    "                                        })\n",
    "\n",
    "net_summary_df = net_summary_df.sort_values('max_loss_optimizer_efficiency')\n",
    "net_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = netdict['0-lr=1 Adam']['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretimagetensor(imgtensor):\n",
    "    ptsdata = list()\n",
    "    for (bindata,age) in getbindatafromimagetensor(imgtensor):\n",
    "        ptdata = str(int(age)) + ' yo, '\n",
    "        for i, val in enumerate(list(bindata)):\n",
    "            if i == 0:\n",
    "                if val == '1':\n",
    "                    ptdata += 'Male, '\n",
    "                else:\n",
    "                    ptdata += 'Female, '\n",
    "            elif val == '1':\n",
    "                ptdata += columns[i] + ', '\n",
    "        ptdata = ptdata[:-2]\n",
    "        ptsdata.append(ptdata)\n",
    "    return ptsdata\n",
    "\n",
    "def getbindatafromimagetensor(imgtensor):\n",
    "    ptsdata = list()\n",
    "    for case in imgtensor:\n",
    "        case = case / 2 + 0.5\n",
    "        case = case.numpy()\n",
    "        case = np.transpose(case, (1, 2, 0))\n",
    "        bindata = ''\n",
    "        for i in range(ndepth-1): bindata += str(int(case[0,0,i]))\n",
    "        for i in range(1,ncolumns - ndepth + 2):\n",
    "            bindata += str(int(case[0,i,ndepth-2]))\n",
    "        age = float(round(float(case[0,0,ndepth-1])*100.))\n",
    "        ptsdata.append((bindata, age))\n",
    "    return ptsdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip training and load saved model\n",
    "checkpoint = torch.load(PATH)\n",
    "net = Net()\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "testimages = checkpoint['testimages']\n",
    "testclasses = checkpoint['testclasses']\n",
    "testindices = checkpoint['testindices']\n",
    "testinitialized = 1\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test random image from test set\n",
    "net.eval()\n",
    "net.cpu()\n",
    "randomstartindex = math.floor(len(testimages)*random())\n",
    "print(randomstartindex)\n",
    "images, labels = gettestdata(randomstartindex)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(images)\n",
    "    ptinfo = interpretimagetensor(images)\n",
    "    for i in range(nminibatchsize):\n",
    "        actlist = list()\n",
    "        predlist = list()\n",
    "        if sum(labels[i]) == 0.:\n",
    "            actlist.append('none')\n",
    "        for j in range(nclasses):\n",
    "            predlist.extend([str(round(100*float(outputs[i,j]),2)) + '% ' + classes[j]])\n",
    "            if labels[i,j] == 1.: actlist.extend([classes[j]])\n",
    "        print(ptinfo[i])\n",
    "        print(predlist)\n",
    "        print(actlist)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fakedata = createfakedata(age=(51,61),conds=['Male','Diabetes','Hypertension'])\n",
    "outputs = net(fakedata)\n",
    "print(interpretimagetensor(fakedata))\n",
    "predlist = list()\n",
    "for i in range(nclasses):\n",
    "    predlist.extend([str(round(100*float(outputs[0,i]),2)) + '% ' + classes[i]])\n",
    "print(predlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelstats = dict()\n",
    "for c in classes:\n",
    "    labelstats[c] = {\n",
    "        \"predprobs\" : list(),\n",
    "        \"age\" : list(),\n",
    "        \"sex\" : list(),\n",
    "        \"conditions\" : list()\n",
    "    }\n",
    "\n",
    "with torch.no_grad():\n",
    "    genfunc = gentestdata(0)\n",
    "    for j, (images,labels) in tqdm(enumerate(genfunc,0),total=len(testimages)):\n",
    "        outputs = net(images)\n",
    "        outcomes = np.array(outputs)\n",
    "        ptinfo = interpretimagetensor(images)\n",
    "        for i, case in enumerate(outcomes):\n",
    "            for k, lab in enumerate(labels[i]):\n",
    "                if lab == 1:\n",
    "                    thisdict = labelstats[classes[k]]\n",
    "                    thisdict['predprobs'].append(list(case))\n",
    "                    thisinfo = ptinfo[i].split(', ')\n",
    "                    thisdict['age'].append(int(thisinfo[0].strip(' yo')))\n",
    "                    thisdict['sex'].append(thisinfo[1])\n",
    "                    thisdict['conditions'].append(thisinfo[2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flatlblstats = {\n",
    "    \"truth\" : list(),\n",
    "    \"predprobs\" : list(),\n",
    "    \"age\" : list(),\n",
    "    \"conditions\" : list()\n",
    "    }\n",
    "\n",
    "with torch.no_grad():\n",
    "    genfunc = gentestdata(0)\n",
    "    for j, (images,labels) in tqdm(enumerate(genfunc,0),total=len(testimages)):\n",
    "        outputs = net(images)\n",
    "        outcomes = np.array(outputs)\n",
    "        ptinfo = interpretimagetensor(images)\n",
    "        for i, case in enumerate(outcomes):\n",
    "            flatlblstats['truth'].append([classes[j] for (j,lab) in enumerate(labels[i]) if lab == 1])\n",
    "            flatlblstats['predprobs'].append(list(case))\n",
    "            thisinfo = ptinfo[i].split(', ')\n",
    "            flatlblstats['age'].append(int(thisinfo[0].strip(' yo')))\n",
    "            if thisinfo[1] == 'Male':\n",
    "                flatlblstats['conditions'].append(thisinfo[1:])\n",
    "            else:\n",
    "                flatlblstats['conditions'].append(thisinfo[2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predsbyage = {\n",
    "    'age': list(),\n",
    "    }\n",
    "actualbyage = {\n",
    "    'age': list(),\n",
    "    }\n",
    "for c in classes:\n",
    "    predsbyage[c] = list()\n",
    "    actualbyage[c] = list()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    predsums = np.zeros(nclasses,dtype=np.float32)\n",
    "    actsums = np.zeros(nclasses,dtype=np.float32)\n",
    "    #actsums *= 10\n",
    "    for j,ag in enumerate(flatlblstats['age']):\n",
    "        if ag == i:\n",
    "            for k, val in enumerate(flatlblstats['predprobs'][j]):\n",
    "                predsums[k] += val\n",
    "            for k, val in enumerate(flatlblstats['truth'][j]):\n",
    "                actsums[classes.index(val)] += 1\n",
    "    predsbyage['age'].append(i)\n",
    "    actualbyage['age'].append(i)\n",
    "    for j, c in enumerate(classes):\n",
    "        predsbyage[c].append(predsums[j])\n",
    "        actualbyage[c].append(actsums[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agedistfromactual = dict()\n",
    "agedistfrompreds = dict()\n",
    "for c in classes:\n",
    "    agedistfromactual[c] = list()\n",
    "    agedistfrompreds[c] = list()\n",
    "    for i,val in enumerate(actualbyage[c]):\n",
    "        agedistfromactual[c].extend([i]*int(val))\n",
    "    for i,val in enumerate(predsbyage[c]):\n",
    "        agedistfrompreds[c].extend([i]*int(round(val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agedf = pd.DataFrame(columns=['age','type','result'])\n",
    "#agedf.loc[0] = pd.Series({'age':0,'type':'Predicted','result':'Deceased'})\n",
    "runi = 0\n",
    "for c in classes:\n",
    "    print('Begin predicted ' + c + ' - %i total records' % (runi))\n",
    "    for i,val in enumerate(agedistfrompreds[c]):\n",
    "        agedf.loc[i+runi] = pd.Series({'age':float(val),'type':'Predicted','result':c})\n",
    "    runi += (i + 1)\n",
    "    print('Begin actual ' + c + ' - %i total records' % (runi))\n",
    "    for i,val in enumerate(agedistfromactual[c]):\n",
    "        agedf.loc[i+runi] = pd.Series({'age':float(val),'type':'Actual','result':c})\n",
    "    runi += (i + 1)\n",
    "\n",
    "print('Complete - %i total records' % (runi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "ax = sns.violinplot(x='result',y='age',hue='type',data=agedf,split=True,inner='quartile')\n",
    "ax.set_title('Actual vs. Predicted Age Distribution by Outcome',fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getactavgsbycondfromdb(condlist, includeSex = 0, minage = 0, maxage = 100):\n",
    "    conn = pyodbc.connect('DSN=covid;UID=seh;PWD=Welcome2020!;')\n",
    "    bindata = ''\n",
    "    for col in columns[1:]:\n",
    "        bindata += '1' if col in condlist else '0'\n",
    "    df = pd.read_sql_query(\"{CALL getLabelsForConditionSetv2 ('\" + bindata + \"',\" + str(includeSex) + \",\" + str(minage) + \",\" + str(maxage) + \")}\",conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getstandarderror(df=pd.DataFrame):\n",
    "    errdf = pd.DataFrame(columns=list(df.axes[1])[1:-1]).add_suffix('_Error')\n",
    "    loc = 0\n",
    "    for r in df.iloc:\n",
    "        errs = list()\n",
    "        N = r['CaseCount']\n",
    "        for c in classes:\n",
    "            errs.append((((int(r[c]*N)*(r[c]-1)**2 + int((1-r[c])*N)*r[c]**2)/(N-1))**0.5)/N**0.5)\n",
    "        errdf.loc[loc] = pd.Series({'Hospitalized_Error':errs[0],'Intubated_Error':errs[1],'Deceased_Error':errs[2],'Pneumonia_Error':errs[3]})\n",
    "        loc += 1\n",
    "    return errdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getconditioncompplotdata(conds1=[],conds2=[],miage=0,maage=100,micnt=0):\n",
    "    agesexconddf = pd.DataFrame(columns=['Age','Sex','Condition','Hospitalized','Intubated','Deceased','Pneumonia'])\n",
    "    mconds1 = list()\n",
    "    mconds2 = list()\n",
    "    if len(conds1) == 0: conds1.append('None')\n",
    "    if len(conds2) == 0: conds2.append('None')\n",
    "    mconds1 = conds1.copy()\n",
    "    mconds1.append('Male')\n",
    "    mconds2 = conds2.copy()\n",
    "    mconds2.append('Male')\n",
    "    loc = 0\n",
    "    actavgs1 = getactavgsbycondfromdb(conds1,0,miage,maage)\n",
    "    actavgs1 = actavgs1.join(getstandarderror(actavgs1))\n",
    "    actavgs1 = actavgs1.loc[actavgs1['CaseCount'] >= micnt]\n",
    "    actavgs2 = getactavgsbycondfromdb(conds2,0,miage,maage)\n",
    "    actavgs2 = actavgs2.join(getstandarderror(actavgs2))\n",
    "    actavgs2 = actavgs2.loc[actavgs2['CaseCount'] >= micnt]\n",
    "    with torch.no_grad():\n",
    "        for a in tqdm(range(miage,maage)):\n",
    "            mdata = np.array(net(createfakedata(age=a,conds=mconds1)))[0]\n",
    "            fdata = np.array(net(createfakedata(age=a,conds=conds1)))[0]\n",
    "            mdata2 = np.array(net(createfakedata(age=a,conds=mconds2)))[0]\n",
    "            fdata2 = np.array(net(createfakedata(age=a,conds=conds2)))[0]\n",
    "            agesexconddf.loc[loc] = pd.Series({'Age':float(a),'Sex':'Male','Condition':', '.join(conds1),'Hospitalized':mdata[0],'Intubated':mdata[1],'Deceased':mdata[2],'Pneumonia':mdata[3]})\n",
    "            loc += 1\n",
    "            agesexconddf.loc[loc] = pd.Series({'Age':float(a),'Sex':'Female','Condition':', '.join(conds1),'Hospitalized':fdata[0],'Intubated':fdata[1],'Deceased':fdata[2],'Pneumonia':fdata[3]})\n",
    "            loc += 1\n",
    "            agesexconddf.loc[loc] = pd.Series({'Age':float(a),'Sex':'Male','Condition':', '.join(conds2),'Hospitalized':mdata2[0],'Intubated':mdata2[1],'Deceased':mdata2[2],'Pneumonia':mdata2[3]})\n",
    "            loc += 1\n",
    "            agesexconddf.loc[loc] = pd.Series({'Age':float(a),'Sex':'Female','Condition':', '.join(conds2),'Hospitalized':fdata2[0],'Intubated':fdata2[1],'Deceased':fdata2[2],'Pneumonia':fdata2[3]})\n",
    "            loc += 1\n",
    "    actavgs1 = actavgs1.loc[actavgs1['Age'] >= min(agesexconddf['Age'])]\n",
    "    actavgs1 = actavgs1.loc[actavgs1['Age'] <= max(agesexconddf['Age'])]\n",
    "    actavgs2 = actavgs2.loc[actavgs2['Age'] >= min(agesexconddf['Age'])]\n",
    "    actavgs2 = actavgs2.loc[actavgs2['Age'] <= max(agesexconddf['Age'])]\n",
    "    return agesexconddf,actavgs1,actavgs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agesexconddf,actavgs1,actavgs2 = getconditioncompplotdata(['Diabetes','Hypertension'],['Tobacco Use'],20,80,20)\n",
    "fig, axs = plt.subplots(2,2,figsize=(15,12),sharex=True,sharey=False)\n",
    "i = 0\n",
    "for k, axi in enumerate(axs):\n",
    "    for j in range(len(axi)):\n",
    "        axe = axi[j]\n",
    "        sns.lineplot(ax=axe, x='Age', y=classes[i], hue='Condition', data=agesexconddf)\n",
    "        axe.errorbar(x='Age',y=classes[i],xerr=5.,yerr=classes[i]+'_Error',ls='None',color='blue',\n",
    "                    data=actavgs1,marker='o')\n",
    "        axe.errorbar(x='Age',y=classes[i],xerr=5.,yerr=classes[i]+'_Error',ls='None',color='orange',\n",
    "                    data=actavgs2,marker='s')\n",
    "        axe.set_title(classes[i])\n",
    "        axe.set_ylabel('Incidence Rate')\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axs = plt.subplots(2,2,figsize=(15,12),sharex=True,sharey=True)\n",
    "custom_lines = [Line2D([0], [0], color='blue', lw=1),\n",
    "                Line2D([0], [0], color='orange', lw=1),\n",
    "                Line2D([0], [0], color='blue', lw=1, dashes=(4.,3.)),\n",
    "                Line2D([0], [0], color='orange', lw=1, dashes=(4.,3.)),\n",
    "                Line2D([0], [0], color='grey', lw=1, dashes=(4.,3.))]\n",
    "i = 0\n",
    "for k, axi in enumerate(axs):\n",
    "    for j in range(2):\n",
    "        axe = axi[j]\n",
    "        sns.distplot(labelstats[classes[i]]['age'], hist = False, kde = True,kde_kws = {'linewidth': 1}\n",
    "                        ,ax=axe,axlabel=classes[i]+' age distributions',color='blue')\n",
    "        sns.distplot(agedistfrompreds[classes[i]], hist = False, kde = True,kde_kws = {'linewidth': 1}\n",
    "                        ,ax=axe,color='orange')\n",
    "        axe.axvline(x=round(np.mean(flatlblstats['age']),1),color='grey',dashes=(4.,3.),lw=1)\n",
    "        axe.axvline(x=round(np.mean(labelstats[classes[i]]['age']),1),color='blue',dashes=(4.,3.),lw=1)\n",
    "        axe.axvline(x=round(np.mean(agedistfrompreds[classes[i]]),1),color='orange',dashes=(4.,3.),lw=1)\n",
    "        axe.legend(custom_lines,('actual ('+str(len(labelstats[classes[i]]['age']))+')','predicted ('+str(len(agedistfrompreds[classes[i]]))+')'\n",
    "                                                        ,'actual mean ('+str(round(np.mean(labelstats[classes[i]]['age']),1))+')'\n",
    "                                                        ,'predicted mean ('+str(round(np.mean(agedistfrompreds[classes[i]]),1))+')'\n",
    "                                                        ,'overall mean ('+str(round(np.mean(flatlblstats['age']),1))+')'))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truthcondheatmap = np.zeros((nclasses,ncolumns),dtype=np.float32)\n",
    "predcondheatmap = np.zeros((ncolumns,nclasses),dtype=np.float32)\n",
    "for i,trth in enumerate(flatlblstats['truth']):\n",
    "    for cond in flatlblstats['conditions'][i]:\n",
    "        for lab in trth:\n",
    "            truthcondheatmap[classes.index(lab),columns.index(cond)] += 1\n",
    "        predcondheatmap[columns.index(cond)] += flatlblstats['predprobs'][i]\n",
    "predcondheatmap = predcondheatmap.T\n",
    "for i in range(nclasses):\n",
    "    truthcondheatmap[i] /= len(labelstats[classes[i]]['age'])\n",
    "    predcondheatmap[i] /= sum(predsbyage[classes[i]])\n",
    "fig, axs = plt.subplots(1,3,figsize=(20,6))\n",
    "sns.heatmap(truthcondheatmap.T,ax=axs[0],yticklabels=columns,xticklabels=classes,annot=True,fmt='.2f')\n",
    "sns.heatmap(predcondheatmap.T,ax=axs[1],yticklabels=False,xticklabels=classes,annot=True,fmt='.2f')\n",
    "sns.heatmap((truthcondheatmap - predcondheatmap).T,ax=axs[2],yticklabels=False,xticklabels=classes,annot=True,fmt='.2f',cmap='bwr',vmin=-0.2,vmax=0.2)\n",
    "fig.suptitle('Input Frequency vs...',fontsize=16)\n",
    "axs[0].title.set_text('Actual Label')\n",
    "axs[1].title.set_text('Normalized Label Predictions')\n",
    "axs[2].title.set_text('Actual Minus Predicted (Model Error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}