{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from itertools import permutations\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pyodbc\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "import math\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "testimages = list()\n",
    "testclasses = list()\n",
    "testindices = list()\n",
    "testinitialized = 0\n",
    "PATH = './test_net1.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create generator function for data acquisition and conversion to torch image format.\n",
    "#function must return a tuple of form (tensor containing 4 images,tensor containing 4 labels)\n",
    "#also builds a test set using a quick and dirty random number method.  this will need to be \n",
    "#improved to balance both the test and train sets across potential labels.\n",
    "conn = pyodbc.connect('DSN=covid;UID=???;PWD=???;')\n",
    "crsr = conn.cursor()\n",
    "crsr.execute(\"{CALL getpydata}\")\n",
    "classes = ('AtHome','Hospitalized','Intubated','HospitalizedDeceased','IntubatedDeceased','Deceased')\n",
    "#0\tAtHome\n",
    "#1\tHospitalized\n",
    "#2\tIntubated\n",
    "#3\tHospitalized,Deceased\n",
    "#4\tIntubated,Deceased\n",
    "#5\tDeceased\n",
    "\n",
    "def nextrow():\n",
    "    rowcnt = 0\n",
    "    imgs = list()\n",
    "    labels = list()\n",
    "    row = [0,1,2]\n",
    "    idx = 0\n",
    "    while row:\n",
    "        while (rowcnt<4):\n",
    "            row = crsr.fetchone()\n",
    "            rowcnt += 1\n",
    "            if row:\n",
    "                icol = 0\n",
    "                irow = 0\n",
    "                imgdata = np.zeros((54,54,3),dtype=np.float32)\n",
    "                for px in permutations(list(row[0]),3):\n",
    "                    imgdata[icol,irow,:] = [float(px[0]),float(px[1]),float(px[2])]\n",
    "                    irow += 1\n",
    "                    if (irow > 52):\n",
    "                        icol += 1\n",
    "                        irow = 0\n",
    "                for age in range(0,100):\n",
    "                    if age <= int(row[1]) + 1:\n",
    "                        imgdata[icol,irow,:] = [0.8,0.8,0.6]\n",
    "                    else:\n",
    "                        break\n",
    "                    irow += 1\n",
    "                    if (irow > 52):\n",
    "                        icol += 1\n",
    "                        irow = 0\n",
    "                imgtensor = TF.normalize(TF.to_tensor(imgdata),(0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                if row[2] == '000':\n",
    "                    labels.append(0)\n",
    "                elif row[2] == '100':\n",
    "                    labels.append(1)\n",
    "                elif row[2] == '110':\n",
    "                    labels.append(2)\n",
    "                elif row[2] == '101':\n",
    "                    labels.append(3)\n",
    "                elif row[2] == '111':\n",
    "                    labels.append(4)\n",
    "                elif row[2] == '001':\n",
    "                    labels.append(5)\n",
    "                imgs.append(imgtensor)\n",
    "            else:\n",
    "                break\n",
    "        if row:\n",
    "            if (testinitialized == 0):\n",
    "                if (random() < 0.1):\n",
    "                    testimages.append(torch.stack(imgs))\n",
    "                    testclasses.append(torch.tensor(labels))\n",
    "                    testindices.append(idx)\n",
    "                else:\n",
    "                    yield torch.stack(imgs),torch.tensor(labels)\n",
    "            elif (idx not in testindices):\n",
    "                yield torch.stack(imgs),torch.tensor(labels)\n",
    "            rowcnt = 0\n",
    "            idx += 1\n",
    "            imgs = list()\n",
    "            labels = list()\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Male','Pneumonia','Pregnant','Diabetes','Asthma','Immunocompromised','Hypertension','Other Disease','Cardiovascular Disease','Obesity','Kidney Disease','Tobacco Use','Contact with Another Case','COPD','Recovered']\n",
    "\n",
    "def interpretimagetensor(imgtensor):\n",
    "    for case in images:\n",
    "        case = case / 2 + 0.5\n",
    "        case = case.numpy()\n",
    "        case = np.transpose(case, (1, 2, 0))\n",
    "        bindata = str(int(case[0,0,0])) + str(int(case[0,0,1])) + str(int(case[0,0,2]))\n",
    "        for i in range(1,13):\n",
    "            bindata += str(int(case[0,i,2]))\n",
    "        age = 0\n",
    "        for p1 in case[51:,:,0]:\n",
    "            for p2 in p1:\n",
    "                if str(p2) == '0.8':\n",
    "                    age += 1\n",
    "        age -= 2\n",
    "        for i, val in enumerate(list(bindata)):\n",
    "            if val == '1':\n",
    "                print(columns[i])\n",
    "        print(age)\n",
    "        #for i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=1600, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=6, bias=True)\n)\n"
    }
   ],
   "source": [
    "#the net below is built from the CIFAR tutorial in pytorch\n",
    "#needs major changes to function correctly in this application\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 3 input image channels, 6 output channels, 5x5 square convolution\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 10 * 10, 120)  # --> found that this had to be 16x10x10 from shape print statements in forward function\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 6) #-->was 10 because number of classes in example was 10.  we have 6 classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(np.shape(x))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(np.shape(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(np.shape(x))\n",
    "        x = x.view(-1, 16 * 10 * 10)\n",
    "        #print(np.shape(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(np.shape(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print(np.shape(x))\n",
    "        x = self.fc3(x)\n",
    "        #print(np.shape(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "#loss function and optimizer were set based on CIFAR example also\n",
    "#need to experiment with different hyperparameters and types\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1,   200] loss: 1.142\n[1,   400] loss: 1.002\n[1,   600] loss: 0.948\n[1,   800] loss: 0.931\n[1,  1000] loss: 0.898\n[1,  1200] loss: 0.825\n[1,  1400] loss: 0.813\n[1,  1600] loss: 0.730\n[1,  1800] loss: 0.794\n[1,  2000] loss: 0.711\n[1,  2200] loss: 0.562\n[1,  2400] loss: 0.698\n[1,  2600] loss: 0.698\n[1,  2800] loss: 0.760\n[1,  3000] loss: 0.702\n[1,  3200] loss: 0.729\n[1,  3400] loss: 0.798\n[1,  3600] loss: 0.807\n[1,  3800] loss: 0.917\n[1,  4000] loss: 0.918\n[1,  4200] loss: 0.935\n[1,  4400] loss: 0.897\n[1,  4600] loss: 0.892\n[1,  4800] loss: 0.984\n[1,  5000] loss: 0.921\n[1,  5200] loss: 0.958\n[1,  5400] loss: 0.830\n[1,  5600] loss: 0.851\n[1,  5800] loss: 0.930\n[1,  6000] loss: 0.867\n[1,  6200] loss: 0.819\n[1,  6400] loss: 0.817\n[1,  6600] loss: 0.762\n[1,  6800] loss: 0.799\n[1,  7000] loss: 0.788\n[1,  7200] loss: 0.746\n[1,  7400] loss: 0.814\n[1,  7600] loss: 0.823\n[1,  7800] loss: 0.778\n[1,  8000] loss: 0.787\n[1,  8200] loss: 0.765\n[1,  8400] loss: 0.771\n[1,  8600] loss: 0.868\n[1,  8800] loss: 0.753\n[1,  9000] loss: 0.798\n[1,  9200] loss: 0.775\n[1,  9400] loss: 0.775\n[1,  9600] loss: 0.777\n[1,  9800] loss: 0.799\n[1, 10000] loss: 0.824\n[1, 10200] loss: 0.785\n[1, 10400] loss: 0.804\n[1, 10600] loss: 0.776\nFinished Training\n"
    }
   ],
   "source": [
    "#train a new model\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(nextrow()):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "testinitialized = 1\n",
    "#save test set and model state dictionary for loading later without training.            \n",
    "torch.save({'model_state_dict':net.state_dict(),\n",
    "            'testimages': testimages,\n",
    "            'testclasses': testclasses,\n",
    "            'testindices': testindices}, PATH)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip training and load saved model\n",
    "checkpoint = torch.load(PATH)\n",
    "net = Net()\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "testimages = checkpoint['testimages']\n",
    "testclasses = checkpoint['testclasses']\n",
    "testindices = checkpoint['testindices']\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create generator function for test set\n",
    "\n",
    "def gettestdata(startindex = 0):\n",
    "    for i,classes in enumerate(testclasses,startindex):\n",
    "        yield testimages[i],classes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of the network on the first 199 test images: 72 %\nAccuracy of the network on the first 399 test images: 73 %\nAccuracy of the network on the first 599 test images: 72 %\nAccuracy of the network on the first 799 test images: 72 %\nAccuracy of the network on the first 999 test images: 72 %\nAccuracy of the network on all 1165 test images: 72 %\n"
    }
   ],
   "source": [
    "#test model accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(gettestdata(0),0):\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if i % 200 == 199:\n",
    "            print('Accuracy of the network on the first %i test images: %d %%' % (i,100 * correct / total))\n",
    "\n",
    "print('Accuracy of the network on all %i test images: %d %%' % (i,100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Home Recovery: 71.5 %, Hospital Stay: 28.2 %, ICU/Intubation: 0.4 %, Death: 3.6 %\nHome Recovery: 11.3 %, Hospital Stay: 88.6 %, ICU/Intubation: 5.8 %, Death: 0.5 %\nHome Recovery: 17.1 %, Hospital Stay: 80.7 %, ICU/Intubation: 12.1 %, Death: 20.6 %\nHome Recovery: 79.5 %, Hospital Stay: 20.4 %, ICU/Intubation: 0.1 %, Death: 1.1 %\nPredicted:                AtHome         Hospitalized         Hospitalized               AtHome\nActual:                   AtHome               AtHome               AtHome               AtHome\n"
    }
   ],
   "source": [
    "#test random image from test set\n",
    "randomstartindex = math.floor(len(testimages)*random())\n",
    "images, labels = next(gettestdata(randomstartindex))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    sm = nn.Softmax()\n",
    "    outcomes = np.array(sm(outputs))\n",
    "    for case in outcomes:\n",
    "        #print(case)\n",
    "        print('Home Recovery: %2.1f %%, Hospital Stay: %2.1f %%, ICU/Intubation: %2.1f %%, Death: %2.1f %%' \n",
    "                % (case[0]*100,sum(case[1:5])*100,(case[2]+case[4])*100,sum(case[3:])*100))\n",
    "    print('Predicted: ', ' '.join('%20s' % classes[predicted[j]] for j in range(4)))\n",
    "    print('Actual:    ', ' '.join('%20s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of AtHome : 92 %\nAccuracy of Hospitalized : 63 %\nAccuracy of Intubated :  0 %\nAccuracy of HospitalizedDeceased :  0 %\nAccuracy of IntubatedDeceased :  0 %\nAccuracy of Deceased :  0 %\n"
    }
   ],
   "source": [
    "#model results by class\n",
    "class_correct = list(0. for i in range(6))\n",
    "class_total = list(0. for i in range(6))\n",
    "with torch.no_grad():\n",
    "    for data in gettestdata(0):\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Male\nRecovered\n69\nMale\nPneumonia\nDiabetes\nHypertension\nObesity\nRecovered\n84\nRecovered\n40\nRecovered\n34\n"
    }
   ],
   "source": [
    "interpretimagetensor(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
